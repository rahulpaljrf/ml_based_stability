# -*- coding: utf-8 -*-
"""ML_stability.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1isM6Mu3WdKadyeSyarnNI78KPMltnS2b
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import xgboost as xgb

# Manually Enter Data
X1 = np.array([2, 2, 2, 4, 4, 4, 6, 6, 6, 8, 8, 8, 10, 10, 10])  # Voltage values
X2 = np.array([20, 25, 30, 20, 25, 30, 20, 25, 30, 20, 25, 30, 20, 25, 30])  # Time values
Y = np.array([101, 120, 124, 100, 123, 131, 120, 125, 124, 130, 140, 132, 125, 123, 120])  # Contact angle values

# Data Augmentation: Generate more samples by adding Gaussian noise
augmented_X, augmented_Y = [], []
augmentation_factor = 200  # Number of augmented samples per original sample
for i in range(len(X1)):
    for j in range(augmentation_factor):
        perturbed_X1 = round(X1[i] + np.random.normal(0, 0.2))  # Add Gaussian noise to X1
        perturbed_X2 = round(X2[i] + np.random.normal(0, 1))    # Add Gaussian noise to X2
        augmented_X.append([perturbed_X1, perturbed_X2])
        augmented_Y.append(Y[i])

# Convert to numpy arrays
X = np.array(augmented_X)
Y = np.array(augmented_Y)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Create and Train the XGBoost Model with Regularization
model = xgb.XGBRegressor(reg_alpha=0.2, reg_lambda=0.01)  # Adjust regularization parameters as needed
model.fit(X_train, y_train)

# Make Predictions
y_pred = model.predict(X_test)

# Model Evaluation
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print("Mean Squared Error (MSE) - Testing:", mse)
print("R-squared (R2) - Testing:", r2)

# Training Accuracy
y_train_pred = model.predict(X_train)
train_mse = mean_squared_error(y_train, y_train_pred)
train_r2 = r2_score(y_train, y_train_pred)
print("Mean Squared Error (MSE) - Training:", train_mse)
print("R-squared (R2) - Training:", train_r2)

# Visualization with Different Styles and Colors for Actual and Predicted Contact Angles
plt.scatter(y_test, y_pred, color='blue', marker='o', label='Predicted')  # Blue color for predicted with 'o' marker
plt.scatter(y_test, y_pred, color='red', marker='x', label='Actual')  # Red color for actual with 'x' marker
plt.plot(y_test, y_test, color='green')  # Green line for the line of unity
plt.xlabel("Measured Contact Angle", fontweight='bold')
plt.ylabel("Predicted Contact Angle", fontweight='bold')
plt.title("XGBoost", fontweight='bold')

# Bold scale on both axes
plt.xticks(fontweight='bold')
plt.yticks(fontweight='bold')

plt.legend(fontsize='large', facecolor='lightgray')
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import xgboost as xgb

# Manually Enter Data
X1 = np.array([2, 2, 2, 4, 4, 4, 6, 6, 6, 8, 8, 8, 10, 10, 10])  # Voltage values
X2 = np.array([20, 25, 30, 20, 25, 30, 20, 25, 30, 20, 25, 30, 20, 25, 30])  # Time values
Y = np.array([101, 120, 124, 100, 123, 131, 120, 125, 124, 130, 140, 132, 125, 123, 120])  # Contact angle values

# Convert to numpy arrays
X = np.column_stack((X1, X2))

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Create and Train the XGBoost Model with Regularization
model = xgb.XGBRegressor(reg_alpha=0.5, reg_lambda=0.5)  # Adjust regularization parameters as needed
model.fit(X_train, y_train)

# Make Predictions
y_pred = model.predict(X_test)

# Model Evaluation
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print("Mean Squared Error (MSE) - Testing:", mse)
print("R-squared (R2) - Testing:", r2)

# Training Accuracy
y_train_pred = model.predict(X_train)
train_mse = mean_squared_error(y_train, y_train_pred)
train_r2 = r2_score(y_train, y_train_pred)
print("Mean Squared Error (MSE) - Training:", train_mse)
print("R-squared (R2) - Training:", train_r2)

# Visualization with Different Styles and Colors for Actual and Predicted Contact Angles
plt.scatter(y_test, y_pred, color='blue', marker='o', label='Predicted')  # Blue color for predicted with 'o' marker
plt.scatter(y_test, y_test, color='red', marker='x', label='Actual')  # Red color for actual with 'x' marker
plt.xlabel("Actual Contact Angle")
plt.ylabel("Predicted Contact Angle")
plt.title("Actual vs. Predicted Contact Angle")
plt.legend()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.ensemble import RandomForestRegressor

# Manually Enter Data
X1 = np.array([2, 2, 2, 4, 4, 4, 6, 6, 6, 8, 8, 8, 10, 10, 10])  # Voltage values
X2 = np.array([20, 25, 30, 20, 25, 30, 20, 25, 30, 20, 25, 30, 20, 25, 30])  # Time values
Y = np.array([101, 120, 124, 100, 123, 131, 120, 125, 124, 130, 140, 132, 125, 123, 120])  # Contact angle values

# Data Augmentation: Generate more samples by adding Gaussian noise
augmented_X, augmented_Y = [], []
augmentation_factor = 200  # Number of augmented samples per original sample
for i in range(len(X1)):
    for j in range(augmentation_factor):
        perturbed_X1 = round(X1[i] + np.random.normal(0, 0.2))  # Add Gaussian noise to X1
        perturbed_X2 = round(X2[i] + np.random.normal(0, 1))    # Add Gaussian noise to X2
        augmented_X.append([perturbed_X1, perturbed_X2])
        augmented_Y.append(Y[i])

# Convert to numpy arrays
X = np.array(augmented_X)
Y = np.array(augmented_Y)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Create and Train the Random Forest Model
model = RandomForestRegressor(random_state=42)
model.fit(X_train, y_train)

# Make Predictions
y_pred = model.predict(X_test)

# Model Evaluation
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print("Mean Squared Error (MSE) - Testing:", mse)
print("R-squared (R2) - Testing:", r2)

# Training Accuracy
y_train_pred = model.predict(X_train)
train_mse = mean_squared_error(y_train, y_train_pred)
train_r2 = r2_score(y_train, y_train_pred)
print("Mean Squared Error (MSE) - Training:", train_mse)
print("R-squared (R2) - Training:", train_r2)

# Visualization with Different Styles and Colors for Actual and Predicted Contact Angles
plt.scatter(y_test, y_pred, color='blue', marker='o', label='Predicted')  # Blue color for predicted with 'o' marker
plt.scatter(y_test, y_pred, color='red', marker='x', label='Actual')  # Red color for actual with 'x' marker
plt.plot(y_test, y_test, color='green')  # Green line for the line of unity
plt.xlabel("Measured Contact Angle", fontweight='bold')
plt.ylabel("Predicted Contact Angle", fontweight='bold')
plt.title("RF", fontweight='bold')

# Bold scale on both axes
plt.xticks(fontweight='bold')
plt.yticks(fontweight='bold')

plt.legend(fontsize='large', facecolor='lightgray')
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.ensemble import RandomForestRegressor

# Manually Enter Data
X1 = np.array([2, 2, 2, 4, 4, 4, 6, 6, 6, 8, 8, 8, 10, 10, 10])  # Voltage values
X2 = np.array([20, 25, 30, 20, 25, 30, 20, 25, 30, 20, 25, 30, 20, 25, 30])  # Time values
Y = np.array([101, 120, 124, 100, 123, 131, 120, 125, 124, 130, 140, 132, 125, 123, 120])  # Contact angle values

# Convert to numpy arrays
X = np.column_stack((X1, X2))

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Create and Train the Random Forest Model
model = RandomForestRegressor(random_state=42)
model.fit(X_train, y_train)

# Make Predictions
y_pred = model.predict(X_test)

# Model Evaluation
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print("Mean Squared Error (MSE) - Testing:", mse)
print("R-squared (R2) - Testing:", r2)

# Training Accuracy
y_train_pred = model.predict(X_train)
train_mse = mean_squared_error(y_train, y_train_pred)
train_r2 = r2_score(y_train, y_train_pred)
print("Mean Squared Error (MSE) - Training:", train_mse)
print("R-squared (R2) - Training:", train_r2)

# Visualization with Different Styles and Colors for Actual and Predicted Contact Angles
plt.scatter(y_test, y_pred, color='blue', marker='o', label='Predicted')  # Blue color for predicted with 'o' marker
plt.scatter(y_test, y_test, color='red', marker='x', label='Actual')  # Red color for actual with 'x' marker
plt.xlabel("Actual Contact Angle")
plt.ylabel("Predicted Contact Angle")
plt.title("Actual vs. Predicted Contact Angle")
plt.legend()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score

# Data
days = np.array([2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 36, 38, 40, 42, 46, 48, 50, 52])
contact_angles = np.array([148, 148, 147.3, 147, 147, 146.8, 146, 145, 144.2, 144, 143.8, 143.6, 143.4, 142, 140, 140, 140, 139, 138.6, 135, 134, 133, 133, 132.6])

# Plotting the data
plt.figure(figsize=(10, 6))
plt.plot(days, contact_angles, marker='o', linestyle='-', color='b')
plt.title('Contact Angle vs Days Immersed in NaCl Solution', fontweight='bold')
plt.xlabel('Days', fontweight='bold')
plt.ylabel('Contact Angle', fontweight='bold')
plt.xticks(fontweight='bold')
plt.yticks(fontweight='bold')
plt.grid(True)
plt.show()

# Reshape data
X = days.reshape(-1, 1)
y = contact_angles

# Linear Regression
linear_model = LinearRegression()
linear_model.fit(X, y)
linear_y_pred = linear_model.predict(X)

# Polynomial Regression (Degree 2)
poly_features_2 = PolynomialFeatures(degree=2)
X_poly_2 = poly_features_2.fit_transform(X)
poly_model_2 = LinearRegression()
poly_model_2.fit(X_poly_2, y)
poly_y_pred_2 = poly_model_2.predict(X_poly_2)

# Polynomial Regression (Degree 3)
poly_features_3 = PolynomialFeatures(degree=3)
X_poly_3 = poly_features_3.fit_transform(X)
poly_model_3 = LinearRegression()
poly_model_3.fit(X_poly_3, y)
poly_y_pred_3 = poly_model_3.predict(X_poly_3)

# Polynomial Regression (Degree 4)
poly_features_4 = PolynomialFeatures(degree=4)
X_poly_4 = poly_features_4.fit_transform(X)
poly_model_4 = LinearRegression()
poly_model_4.fit(X_poly_4, y)
poly_y_pred_4 = poly_model_4.predict(X_poly_4)

# Polynomial Regression (Degree 5)
poly_features_5 = PolynomialFeatures(degree=5)
X_poly_5 = poly_features_5.fit_transform(X)
poly_model_5 = LinearRegression()
poly_model_5.fit(X_poly_5, y)
poly_y_pred_5 = poly_model_5.predict(X_poly_5)

# Visualization
plt.figure(figsize=(10, 6))
plt.scatter(X, y, color='red', label='Actual Data')
plt.plot(X, linear_y_pred, color='blue', label='Linear Regression')
plt.plot(X, poly_y_pred_2, color='green', label='Polynomial Regression (Degree 2)')
plt.plot(X, poly_y_pred_3, color='orange', label='Polynomial Regression (Degree 3)')
plt.plot(X, poly_y_pred_4, color='purple', label='Polynomial Regression (Degree 4)')
plt.plot(X, poly_y_pred_5, color='cyan', label='Polynomial Regression (Degree 5)')
plt.xlabel('Days Immersed in NaCl Solution', fontweight='bold')
plt.ylabel('Contact Angle', fontweight='bold')
plt.title('Contact Angle vs Days Immersed', fontweight='bold')
plt.xticks(fontweight='bold')
plt.yticks(fontweight='bold')
plt.legend(fontsize='large', facecolor='lightgray', edgecolor='black', framealpha=1, loc='upper right', shadow=True)
plt.grid(True)
plt.show()

# Calculate MSE and R2 for Linear Regression
linear_mse = mean_squared_error(y, linear_y_pred)
linear_r2 = r2_score(y, linear_y_pred)
print("Linear Regression:")
print("Mean Squared Error (MSE):", linear_mse)
print("R-squared (R2):", linear_r2)
print()

# Calculate MSE and R2 for Polynomial Regression (Degree 2)
poly_mse_2 = mean_squared_error(y, poly_y_pred_2)
poly_r2_2 = r2_score(y, poly_y_pred_2)
print("Polynomial Regression (Degree 2):")
print("Mean Squared Error (MSE):", poly_mse_2)
print("R-squared (R2):", poly_r2_2)
print()

# Calculate MSE and R2 for Polynomial Regression (Degree 3)
poly_mse_3 = mean_squared_error(y, poly_y_pred_3)
poly_r2_3 = r2_score(y, poly_y_pred_3)
print("Polynomial Regression (Degree 3):")
print("Mean Squared Error (MSE):", poly_mse_3)
print("R-squared (R2):", poly_r2_3)
print()

# Calculate MSE and R2 for Polynomial Regression (Degree 4)
poly_mse_4 = mean_squared_error(y, poly_y_pred_4)
poly_r2_4 = r2_score(y, poly_y_pred_4)
print("Polynomial Regression (Degree 4):")
print("Mean Squared Error (MSE):", poly_mse_4)
print("R-squared (R2):", poly_r2_4)
print()

# Calculate MSE and R2 for Polynomial Regression (Degree 5)
poly_mse_5 = mean_squared_error(y, poly_y_pred_5)
poly_r2_5 = r2_score(y, poly_y_pred_5)
print("Polynomial Regression (Degree 5):")
print("Mean Squared Error (MSE):", poly_mse_5)
print("R-squared (R2):", poly_r2_5)

# Transform the day value (180) using polynomial features
X_180 = np.array([[122]])

# Linear Regression
linear_y_pred_180 = linear_model.predict(X_180)
print("Predicted contact angle at 180 days (Linear Regression):", linear_y_pred_180[0])

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score

# Temperature data (in degrees) and corresponding contact angles
temp_degrees = np.array([0, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 200, 210, 220, 230, 240, 250, 260])
contact_angles = np.array([148, 148, 148, 146, 145.3, 142.2, 130.6, 130, 129, 128.8, 128.6, 128.5, 128.3, 128.1, 128.1, 128, 128, 127.8, 127.8, 127.7, 127.7, 127.7, 127.6])

# Reshape data for modeling
X = temp_degrees.reshape(-1, 1)
y = contact_angles

# Linear Regression
linear_model = LinearRegression()
linear_model.fit(X, y)
linear_y_pred = linear_model.predict(X)

# Polynomial Regression (Degree 2 to 5)
degrees = [2, 3, 4, 5]
plt.figure(figsize=(10, 6))
plt.scatter(X, y, color='red', label='Actual Data')
plt.plot(X, linear_y_pred, color='blue', label='Linear Regression')

for degree in degrees:
    poly_features = PolynomialFeatures(degree=degree)
    X_poly = poly_features.fit_transform(X)
    poly_model = LinearRegression()
    poly_model.fit(X_poly, y)
    poly_y_pred = poly_model.predict(X_poly)

    # Plot Polynomial Regression
    plt.plot(X, poly_y_pred, label=f'Polynomial Regression (Degree {degree})')

plt.xlabel('Temperature (degrees)')
plt.ylabel('Contact Angle')
plt.title('Contact Angle vs Temperature')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score

# Temperature data (in degrees) and corresponding contact angles
temp_degrees = np.array([0, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 200, 210, 220, 230, 240, 250, 260])
contact_angles = np.array([148, 148, 148, 146, 145.3, 142.2, 130.6, 130, 129, 128.8, 128.6, 128.5, 128.3, 128.1, 128.1, 128, 128, 127.8, 127.8, 127.7, 127.7, 127.7, 127.6])

# Reshape data for modeling
X = temp_degrees.reshape(-1, 1)
y = contact_angles

# Linear Regression
linear_model = LinearRegression()
linear_model.fit(X, y)
linear_y_pred = linear_model.predict(X)

# Polynomial Regression (Degree 2 to 5)
degrees = [2, 3, 4, 5]
plt.figure(figsize=(10, 6))
plt.scatter(X, y, color='red', label='Actual Data')
plt.plot(X, linear_y_pred, color='blue', label='Linear Regression')

for degree in degrees:
    poly_features = PolynomialFeatures(degree=degree)
    X_poly = poly_features.fit_transform(X)
    poly_model = LinearRegression()
    poly_model.fit(X_poly, y)
    poly_y_pred = poly_model.predict(X_poly)

    # Plot Polynomial Regression
    plt.plot(X, poly_y_pred, label=f'Polynomial Regression (Degree {degree})')

plt.xlabel('Temperature (degrees)', fontweight='bold')
plt.ylabel('Contact Angle', fontweight='bold')
plt.title('Contact Angle vs Temperature', fontweight='bold')
plt.xticks(fontweight='bold')
plt.yticks(fontweight='bold')
plt.legend(fontsize='large', facecolor='lightgray', edgecolor='black', framealpha=1, loc='upper right', shadow=True)
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score

# pH levels and corresponding contact angles
pH_levels = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])
contact_angles = np.array([148, 148, 147.8, 147.4, 147.3, 147.2, 147, 146, 144, 140, 138, 137.6, 136.2, 136.1, 136.1])

# Reshape data for modeling
X = pH_levels.reshape(-1, 1)
y = contact_angles

# Linear Regression
linear_model = LinearRegression()
linear_model.fit(X, y)
linear_y_pred = linear_model.predict(X)

# Polynomial Regression (Degree 2)
poly_features_2 = PolynomialFeatures(degree=2)
X_poly_2 = poly_features_2.fit_transform(X)
poly_model_2 = LinearRegression()
poly_model_2.fit(X_poly_2, y)
poly_y_pred_2 = poly_model_2.predict(X_poly_2)

# Polynomial Regression (Degree 3)
poly_features_3 = PolynomialFeatures(degree=3)
X_poly_3 = poly_features_3.fit_transform(X)
poly_model_3 = LinearRegression()
poly_model_3.fit(X_poly_3, y)
poly_y_pred_3 = poly_model_3.predict(X_poly_3)

# Plotting
plt.figure(figsize=(10, 6))
plt.scatter(X, y, color='blue', label='Actual Data')
plt.plot(X, linear_y_pred, color='red', label='Linear Regression')
plt.plot(X, poly_y_pred_2, color='green', label='Polynomial Regression (Degree 2)')
plt.plot(X, poly_y_pred_3, color='orange', label='Polynomial Regression (Degree 3)')
plt.title('Contact Angle vs pH Level', fontweight='bold')
plt.xlabel('pH Level', fontweight='bold')
plt.ylabel('Contact Angle', fontweight='bold')
plt.xticks(fontweight='bold')
plt.yticks(fontweight='bold')
plt.grid(True)
plt.legend(fontsize='large', facecolor='lightgray', edgecolor='black', framealpha=1, loc='upper right', shadow=True)
plt.show()

# Evaluate Linear Regression
mse_linear = mean_squared_error(y, linear_y_pred)
r2_linear = r2_score(y, linear_y_pred)
print("Linear Regression:")
print("Mean Squared Error (MSE):", mse_linear)
print("R-squared (R2):", r2_linear)

# Evaluate Polynomial Regression (Degree 2)
mse_poly_2 = mean_squared_error(y, poly_y_pred_2)
r2_poly_2 = r2_score(y, poly_y_pred_2)
print("Polynomial Regression (Degree 2):")
print("Mean Squared Error (MSE):", mse_poly_2)
print("R-squared (R2):", r2_poly_2)

# Evaluate Polynomial Regression (Degree 3)
mse_poly_3 = mean_squared_error(y, poly_y_pred_3)
r2_poly_3 = r2_score(y, poly_y_pred_3)
print("Polynomial Regression (Degree 3):")
print("Mean Squared Error (MSE):", mse_poly_3)
print("R-squared (R2):", r2_poly_3)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score

# Data: Number of cycles (e) and corresponding contact angles (CA)
cycles = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 40, 50, 60, 90, 120, 140, 160, 180, 200, 250, 280, 300])
contact_angles = np.array([148, 148, 147.8, 147.6, 147.5, 146.2, 145.6, 145.5, 145.3, 145.3, 140.3, 135.6, 130.2, 126, 123.9, 119.8, 119.6, 115, 113, 112.3, 112.3, 110, 107.4])

# Plotting the data
plt.figure(figsize=(10, 6))
plt.scatter(cycles, contact_angles, color='blue', label='Actual Data')
plt.title('Contact Angle vs Number of Abrasion Cycles', fontweight='bold')
plt.xlabel('Number of Abrasion Cycles', fontweight='bold')
plt.ylabel('Contact Angle', fontweight='bold')
plt.grid(True)
plt.xticks(fontweight='bold')
plt.yticks(fontweight='bold')
plt.legend(fontsize='large', facecolor='lightgray', edgecolor='black', framealpha=1, loc='upper right', shadow=True)

# Reshape data for modeling
X = cycles.reshape(-1, 1)
y = contact_angles

# Linear Regression
linear_model = LinearRegression()
linear_model.fit(X, y)
linear_y_pred = linear_model.predict(X)

# Polynomial Regression
degrees = [2, 3]
colors = ['green', 'orange']

for i, degree in enumerate(degrees):
    poly_features = PolynomialFeatures(degree=degree)
    X_poly = poly_features.fit_transform(X)
    poly_model = LinearRegression()
    poly_model.fit(X_poly, y)
    poly_y_pred = poly_model.predict(X_poly)

    # Plot Polynomial Regression
    plt.plot(X, poly_y_pred, color=colors[i], label=f'Polynomial Regression (Degree {degree})')

# Plot Linear Regression
plt.plot(X, linear_y_pred, color='red', label='Linear Regression')
plt.legend(fontsize='large', facecolor='lightgray', edgecolor='black', framealpha=1, loc='upper right', shadow=True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score

# Data: Number of cycles (e) and corresponding contact angles (CA)
cycles = np.array([1, 2, 3, 4, 5, 6, 7, 10, 9, 10, 20, 40, 50, 60, 90, 120, 140, 160, 180, 200, 250, 280, 300])
contact_angles = np.array([148, 148, 147.8, 147.6, 147.5, 146.2, 145.6, 145.5, 145.3, 145.3, 140.3, 135.6, 130.2, 126, 123.9, 119.8, 119.6, 115, 113, 112.3, 112.3, 110, 107.4])

# Reshape data for modeling
X = cycles.reshape(-1, 1)
y = contact_angles

# Define degrees for polynomial regression
degrees = [2, 3]

best_model = None
best_mse = float('inf')  # Initialize with a large value

# Fit and evaluate Polynomial Regression models
for degree in degrees:
    poly_features = PolynomialFeatures(degree=degree)
    X_poly = poly_features.fit_transform(X)

    # Polynomial Regression
    poly_model = LinearRegression()
    poly_model.fit(X_poly, y)
    poly_y_pred = poly_model.predict(X_poly)

    # Evaluate Polynomial Regression
    mse_poly = mean_squared_error(y, poly_y_pred)
    r2_poly = r2_score(y, poly_y_pred)

    # Print evaluation metrics
    print(f"Polynomial Regression (Degree {degree}):")
    print("Mean Squared Error (MSE):", mse_poly)
    print("R-squared (R2):", r2_poly)
    print()

    # Keep track of the best model (lowest MSE)
    if mse_poly < best_mse:
        best_mse = mse_poly
        best_model = poly_model

# Predict contact angle at 350 cycles using the best model
cycles_to_predict = np.array([350]).reshape(-1, 1)
X_poly_predict = poly_features.transform(cycles_to_predict)  # Transform for prediction
contact_angle_predicted = best_model.predict(X_poly_predict)

# Print predicted contact angle
print(f"Predicted contact angle at 350 abrasion cycles: {contact_angle_predicted[0]:.2f}")

